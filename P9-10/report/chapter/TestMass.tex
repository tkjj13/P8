\chapter{Testing of Massive IoT system} \label{ch:mass_test}
The focus of this chapter is to showcase the emulator described in \autoref{ch:MassOver}. This is done in a series of test, where it is compared to the original code and to see if the changes made fulfill the goal set in \autoref{ch:MassOver}:

To emulate a massive amount of device, which do not interfere with each others workload and produce the same results as the baseline.

The is is done by comparing the changed code to the baseline code as well as testing the performance of the code at higher number of devices emulated.
The performance criteria that will be look into is:

\begin{itemize}
\item Error rate
\item Execution time
\item CPU usage
\item Memory usage
\end{itemize}

The error rate will showcase the stability of the code. This is done by running the code multiple times and to analyze the errors occurring. The errors can be analyzed from the log files.

The execution time is looked into to see if any processes in the code is taking longer, after the changes. This is measured by logging the time stamps, where the code goes from one step to another. 

CPU and memory usage is used to test for possible bottlenecks. CPU usage will be measure with the CPU stat tool, which can measure the CPU usage on the individual processes at a sample rate of 3 Hz. The memory usage is measured using the system monitor tool, as all bigger buffers is allocated in the initialization and the used memory therefore is nearly static. 

The parameters used for the eNB and SRS code is the default settings shown in \appref{app:Amarisoft} and \appref{app:SRSconfig}. The emulator is executed 20 times each time the number of devices is increased until the emulator hit 100\% in error rate multiple times in a row. Besides testing the emulator with the changed code, the baseline code is also tested, this is what the code is matched against. Note that baseline code can only emulate one device, the results will be extrapolated for comparison with multiple devices though.

\section{Error rate}
\label{sec:MTerror}
The error rate is analyzed from the log messages coming from the emulator on its process through the code. These result can be seen in \autoref{fig:MT_error}.

\begin{figure}[H]
\tikzsetnextfilename{MT_error}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MT_error.tex}}
\caption{Error rate for different amount of devices.}
\label{fig:MT_error}
\end{figure}

As it can be seen in \autoref{fig:MT_error}, the error rate is higher for the changed code, than the baseline that still is not perfect. Another important aspect is that when the number of devices hit 13, the error rate goes to 100\%, which shows the limit of the emulator. A more detailed overview of these error show that six different types of errors occur during the testing as shown in \autoref{fig:MT_error_dist}.

\begin{figure}[H]
\tikzsetnextfilename{MT_error_dist}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_error_dist.tex}}
\caption{The distribution of different errors for different amount of devices.}
\label{fig:MT_error_dist}
\end{figure}

Radio error comes from miscommunication between the radio class and the API for the USRP B210. It occur when the process begins the search for  SIB messages, where some radio parameters is changed. As the radio error is the only error occurring for the baseline, this should be the only error that is not produced by the changed made to the baseline.

The idle after MIB error occur in the same part of the process as the radio error, where the emulator gets stuck and runs without retrying or closing down. This error type is the most occurring type of the errors produced by the changes, which will be the most optimal place to improve the error rate, especially for higher amount of devices.

The msg2 not received error is when all devices have gone through the NPRACH step and waiting on the msg2, which is never received or not registered if received. This error is very rare and have no tendencies.

Cell sync error occur when the emulator shuts down before the device has synchronized to the cell and it goes to the MIB step. This error is very rare, but as the error occurs so early in the process, these test runs will not give any data for any other step, beside initialization.

Transmission after SIB1 is an error that occurs sometimes at the SIB1 step and the radio class transmit a signal, which causes the emulator to shut down. This error type have a tendency to occur with higher amount of devices and can indicate a bottleneck in the process to get a higher amount of devices.

NPRACH error is an error that occurs when some devices completes the NPRACH step, but other do not, as the system shuts down beforehand. This error type have the same tendency as the transmission after SIB1 error and also indicates a potential bottleneck.

\section{Execution time}
\label{sec:exeTime}
To test the execution time for the emulator, the test will be split up into the different steps in the code process discussed in \autoref{sub:MassStruct}.

\subsection{Initialization}
The execution time for the initialization step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_Init_Time}.


\begin{figure}[H]
\tikzsetnextfilename{MT_Init_Time}
\centering
\resizebox{0.7\textwidth}{!}{
\input{figures/MT_Init_Time.tex}}
\caption{Execution time for the initialization for different amount of devices and the baseline. The fitted line is a linear approximation.}
\label{fig:MT_Init_Time}
\end{figure}

From \autoref{fig:MT_Init_Time} it can be seen that there is a linear tendency scaling with the number of devices. It is also seen that even if the baseline and the changed code emulates one device, the baseline have a lower execution time, with a estimated difference to be the same as a single step between different number of devices. The fitted line is estimated to be:

\begin{align}
&T_{init} (\text{NoD}) = 0.0942 \cdot \text{NoD} + 1.526 [s]
\end{align}
\begin{where}
\va{$T_{Init}$}{is the execution time for the initialization step}{s}
\va{$\text{NoD}$}{is the number of devices emulated}{$\cdot$}
\end{where}


\subsection{Synchronization}
The execution time for the synchronization step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_Sync_Time}. As the error type cell sync, mention in \autoref{sec:MTerror}, occurs in this step of the process, some measurements will be equal zero, as the execution time can not be calculated. As when an error occur, will the measurement end, which impact the number of measurement point further on.

\captionsetup{belowskip=0em}
\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_Sync_Time}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_Sync_Time.tex}}
\caption{Execution time for the synchronization for different amount of devices and the baseline}
\label{fig:MT_Sync_Time}
\end{figure}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_Sync_His}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_Sync_His.tex}}
\caption{The distribution for the execution time for synchronization for all different amount of devices}
\label{fig:MT_Sync_His}
\end{figure}
\end{minipage}
\captionsetup{belowskip=-1.5em}

As seen in \autoref{fig:MT_Sync_Time} is the execution time for different amount of devices is behaving equal to each other. Another aspect seen on the figure is that some measurements have taken some extra time to execute, but is align at the same time values, which also indicated on the histogram in \autoref{fig:MT_Sync_His}. Here it is seen that most measurements is placed at 0.6 s to 0.8 s and the amount at the other points is much lower.



\subsection{MIB decoding}
The execution time for the MIB decoding step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_MIB_Time}. All these measurements is for a full decoding of MIB and all retries have been removed.


\captionsetup{belowskip=0em}
\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_MIB_Time}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_MIB_Time.tex}}
\caption{Execution time for the decoding the MIB for different amount of devices and the baseline. A single measurement for the base line is placed at 5.0834 s, which is not shown on this figure.}
\label{fig:MT_MIB_Time}
\end{figure}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_MIB_His}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_MIB_His.tex}}
\caption{The distribution for the execution time for decoding the MIB for all different amount of devices.}
\label{fig:MT_MIB_His}
\end{figure}
\end{minipage}
\captionsetup{belowskip=-1.5em}

As seen in \autoref{fig:MT_MIB_Time} the execution time for the MIB decoding step have the same tendency across different amount of devices. The spread is bigger compared to the synchronazitation step, which also can be seen when comparing the histogram for the two steps, \autoref{fig:MT_Sync_His} and \autoref{fig:MT_MIB_His}. The baseline have the same tendency as the changed code, which indicates that the changes do not effect this step. In \autoref{fig:MT_MIB_Tries} is it shown how many attempts the different measurements needed before completing the MIB decoding step.

\begin{figure}[H]
\tikzsetnextfilename{MT_MIB_Tries}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MT_MIB_Tries.tex}}
\caption{The distribution for number of attempts for decoding the MIB for different amount of devices.}
\label{fig:MT_MIB_Tries}
\end{figure}

It is seen in \autoref{fig:MT_MIB_Tries} that baseline code is not different from the changed code at a lower amount of devices. At a higher amount of devices it seems like the changed code is more efficient, as these levels is the amount of attempts lower.

\subsection{SIB1}
The execution time for the SIB1 decoding step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_SIB1_Time}. The test is executed with the different amount of devices, but the results shown in \autoref{fig:MT_SIB1_Time} is only for the first device which also will be the procedure for the following step. This is done, so all number of device have the same stand point compared to the measurements.
As both the radio error and idle after MIB error occurs in this step of the process, the amount of measurement points are lowered.

\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_SIB1_Time}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/MT_SIB1_Time.tex}}
\caption{Execution time for the decoding the SIB1 step for different amount of devices and the baseline.}
\label{fig:MT_SIB1_Time}
\end{figure}
\end{minipage}%
\hfill
\begin{minipage}{0.48\textwidth}
\begin{figure}[H]
\tikzsetnextfilename{MT_SIB1_His}
\centering
\resizebox{0.9\textwidth}{!}{
\input{figures/Hist_SIB1.tex}}
\caption{Execution time for the decoding the SIB1 step for different amount of devices and the baseline.}
\label{fig:MT_SIB1_His}
\end{figure}
\end{minipage}

As seen in \autoref{fig:MT_SIB1_Time} the baseline and changed code have the same tendency around four different time values, with some measurements way off. Compared to the previous steps, this step have long execution time and the steps between the time values is around 600 ms. In \autoref{fig:MT_SIB1_His} can the distribution be seen, where it is seen that the values is equal distributed between the four different time values. This indicated that the code begins the search at four different times, compared to the repeating of the SIB1 message.


\subsection{SIB2}
The execution time for the SIB2 decoding step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_SIB2_Time}. The transmission after SIB1 error narrows the number of measurement points down even further for this step in the process.

\begin{figure}[H]
\tikzsetnextfilename{MT_SIB2_Time}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MT_SIB2_Time.tex}}
\caption{Execution time for the decoding the SIB2 step for different amount of devices and the baseline.}
\label{fig:MT_SIB2_Time}
\end{figure}


As seen in \autoref{fig:MT_SIB2_Time} do the baseline and changed code have the same tendency, beside for when there is emulated 15 devices. There is not a big spread for the measurements for all the other setups, which is also expected as the timing between decoding SIB1 and SIB2 should only be the time until the whole SIB2 have been received with some additional time for the decoding.

\subsection{NPRACH}
The execution time for the NPRACH step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_Nprach_Time}. Here will the NPRACH error occur for some of the measurements and will effect the results. As mention earlier are the shown results only for the first device and the NPRACH error happens when some devices get through the NPRACH step, but not all.

\begin{figure}[H]
\tikzsetnextfilename{MT_Nprach_Time}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MT_Nprach_Time.tex}}
\caption{Execution time for the NPRACH step for different amount of devices and the baseline.}
\label{fig:MT_Nprach_Time}
\end{figure}

As seen in \autoref{fig:MT_Nprach_Time} the baseline and changed code takes approximately the same time, but the changed code have a bigger spread of its measurement point. All the measurements of the changed code over 12 devices, however does not follow the tendency of the other measurements, which should come from the fact, that all the shown measurement points for these number of devices, is measurements where the NPRACH error occurred and none of them made it error free through, as seen in \autoref{fig:MT_error_dist}.

\subsection{RAR}
The execution time for the RAR step is measured dependably on the number of devices emulated and the baseline is measured as well, which gives the results seen in \autoref{fig:MT_Rar_Time}. Here does the msg2 error occurs if no msg2 is received and the measurements are therefore to be excluded.

\begin{figure}[H]
\tikzsetnextfilename{MT_Rar_Time}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MT_Rar_Time.tex}}
\caption{Execution time for the decoding the MIB for different amount of devices and the baseline. A single measurement for the base line is placed at 5.0834 s, which is not shown on this figure.}
\label{fig:MT_Rar_Time}
\end{figure}

As seen in \autoref{fig:MT_Rar_Time} the changed code starts out with following the tendency for the baseline, but around eight devices it begin to get a higher and higher execution time and getting a wider spread compared to the values at a low amount of devices, which indicates a possible bottleneck in the system.

\subsection{Summary}
For the comparison between the baseline compared to massive emulator, when looking at the execution time, is that in most step, the two emulator perform similar. The initialization steps is where the biggest difference is, but as the extra workload from a higher amount of devices do not happens parallel, is this expected. A bottleneck that can be seen in these test, comes in the RAR step, where a higher delay is seen when the number of devices hits eight or higher. The results from 13 to 15 device do act as the other measurements, but with no successful runs, is this expected as well.


\section{CPU usage}
To test the CPU usage for the emulator, the test will be split up into the different steps in the code process discussed in \autoref{sub:MassStruct}. 

The results will be shown as average CPU usage over the steps time period, as the executing time is not equal for all measurement. The same error will occur in same places as descriped thorugh \autoref{sec:exeTime} and the measurement points which have an error will not be in the following steps.

The sample rate is as mention before at 3 Hz, which is a slow sample rate, compared to the execution time for the different steps. But it have not been possible to find a tool that gave a higher sample frequency.

The RAR step have a to small time window to measure with a 3 Hz sample rate, so it have not been measured.

\subsection{Initialization}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the initialization step.

\begin{figure}[H]
\tikzsetnextfilename{CPU_init}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/Initialization.tex}}
\caption{CPU usage for the initialization step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_init}
\end{figure}

As seen in \autoref{fig:CPU_init}, is that the average CPU usage is rising with the number of devices used, which indicates that at some point it will hit full usage and the linear tendency, seen in \autoref{fig:MT_Init_Time} from the execution time measurement, will rise more, when it hits that point. But as the initialization will not affect the rest of the process, is this not considered a problem.

\subsection{Synchronization}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the synchronization step.

\begin{figure}[H]
\tikzsetnextfilename{CPU_sync}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/Cell_Search.tex}}
\caption{CPU usage for the synchronization step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_sync}
\end{figure}

As seen in \autoref{fig:CPU_sync}, average CPU usage is rising with the number of devices used, is a problem, as it will hit full usage at some point, which can effect the ability to synchronize with the cell. The increase in CPU usage can be explain with the higher number of threads that is running in all the higher layer classes in the devices.

\subsection{Decoding of MIB}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the decoding of MIB step. The measurements are taken from last attempt to decode the MIB to it is done.

\begin{figure}[H]
\tikzsetnextfilename{CPU_MIB}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/MIB.tex}}
\caption{CPU usage for the decoding of MIB step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_MIB}
\end{figure}

As seen in \autoref{fig:CPU_MIB}, is the tendency the same as with the synchronization step, but with bigger spread on the results. The spread is expected to be cause by the big spread in execution time for this step, while the workload is the same, when looking at the decoding part. This tendency of a rising CPU usage compare to the number of devices will cause the same problem as mention before at the synchronization step and with the same cause.

\subsection{SIB1}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the SIB1 step. As also done in \autoref{sec:exeTime}, will the measurements only be for the first device, for the same reasons.

\begin{figure}[H]
\tikzsetnextfilename{CPU_SIB1}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/SIB1.tex}}
\caption{CPU usage for the SIB1 step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_SIB1}
\end{figure}

As seen in \autoref{fig:CPU_SIB1}, does this step also have a higher CPU usage at higher number of devices. It is also seen that the CPU usage is raising above 100\%, but as there is multiple threads in work at this point, multiple kernels is also in use, where the CPU usage for each kernel is combine to this results. With a eight kernel CPU and with the approximation that one kernel should be use for other purposes, it will give a upper limit to be 700\% or the results here should be divide by seven. But the tendency of increasing CPU usage will as with the other cases be a bottleneck at a high enough number of devices. The reason for so much higher increase in CPU usage, compared to the previous steps, is that all device works at this point, compared to the previous two, were it only was the Co\_Phy working.

\subsection{SIB2}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the SIB2 step.

\begin{figure}[H]
\tikzsetnextfilename{CPU_SIB2}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/SIB2.tex}}
\caption{CPU usage for the SIB2 step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_SIB2}
\end{figure}

As seen in \autoref{fig:CPU_SIB2}, do the results point at the same problems as for the SIB1 step. A point there can be pointed out for the SIB2 case, is that there looks to be two tendencies, on above the red fitting line and one below. As the SIB2 step contains two parts, which is looking for the SIB2 message and then decode it, where the later half is the CPU usage heavy one, and the time used is so small compared to the sample rate (four samples at max), can give a very spread results. 

\subsection{NPRACH}
In \autoref{fig:CPU_init} is seen the CPU usage measurements for the SIB2 step.

\begin{figure}[H]
\tikzsetnextfilename{CPU_NPRACH}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/NPRACH.tex}}
\caption{CPU usage for the NPRACH step for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:CPU_NPRACH}
\end{figure}

As seen in \autoref{fig:CPU_NPRACH}, do it follow the same tendencies as the other steps. As the NPRACH step is even shorter in time that the  SIB2 step (1-2 samples) the spread is even wider than at the previous step.

\subsection{Summary}
At all steps in the process is there a tendency to an increase in CPU usage compared to the number of devices, which will be a bottleneck when the system hit that amount of devices to hit full usage. In \autoref{tab:NoDCPU} can the amount of devices to hit this limit be seen for the different steps. The number is calculated from the linear approximation, shown in all the plot through this section.

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|}
\hline
Steps & CPU kernels & NoD \\
\hline
Initialization & 1 & 27 \\
\hline
Synchronization & 1 & 43 \\
\hline
Decoding of MIB & 1 & 73 \\
\hline
SIB1 & 1 & 67 \\
\hline
SIB2 & 1 & 112 \\
\hline
NPRACH & 1 & 124 \\
\hline
\end{tabular}
\caption{Number of devices to hit full CPU usage for the different steps.}
\label{tab:NoDCPU}
\end{table}

\section{Memory usage}
To test the memory usage, the massive emulator is run once for each number of devices, as well for the baseline. As all the buffer and bigger arrays reserve space in the memory in the initialization step, do the amount of memory use not change from run to run, but changes compared to many devices there is meant to be emulated. The results can be seen in \autoref{fig:RAMusage}.

\begin{figure}[H]
\tikzsetnextfilename{RAMusage}
\centering
\resizebox{0.5\textwidth}{!}{
\input{figures/RAMusage.tex}}
\caption{Memory usage for the whole process for different amount of devices and the baseline. The fitted line is a linear approximation}
\label{fig:RAMusage}
\end{figure}

As seen in \autoref{fig:RAMusage}, does the memory usage follow a very linear tendency. This makes sense, as all the whole structure is multiplied with the number of device and therefore also the memory usage. The reason for the difference between the baseline and a single device, is the that the Co Phy use as much space as a normal device, as describe in \autoref{sec:Changes}. With the computer use for the project, the limit for number of devices that can emulated, when only looking at the memory usage, is 108 devices.



