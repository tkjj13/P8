\chapter{Discussion}
The discussion will follow up on the results found in \autoref{ch:mass_test} and \autoref{ch:BatTest} and suggestions are made to explain some of the findings, as well as some of the potential problems that might influence the results. 

\section{Domain: Massiveness}
It was found in \autoref{ch:mass_test} that the MDE could emulate up to 12 devices, with an error rate around the 30 $\%$. While the number of  devices is not as high as wanted, does the other three test criteria test show results that indicates that the system can handle more devices, which indicates that the compurter is not limiting factor at this point. 

Looking into the MDE, multi issues can be addressed. The biggest concern that have been with the MDE, is that its baseline was an in-development project, which have given some errors, like a struct containing the cell parameters could not initialize. Errors like these have meant that implementing new functionalities into the system have been difficult, as when a new error occurred, it was not known if it was the implementation fault or the baseline code had a problem with this new functionality. Another problem with the baseline, is that based on the LTE version, used in the previous project and the structure is very similar to the version, but with a lot of classes and functionalities still left from LTE. This have made debugging very hard and have given the project a very slow learning curve to understand the code, when half of the +60 classes is not use.

When looking away from the fact that the baseline still is in development, have some implementation not work just as well as aspected. The most occuring error, as seen in \todo{ref}, is the \textit{ilde after MIB-NB}, an error not found in baseline. Under the testing phase of MDE and the baseline, it is seen that the baseline call a function in the RRC class, which restart the whole synchronization step, which does not happen in the MDE. This comes from the fact, mentioned in \autoref{ch:MassOver}, is that instead of starting the attach procedure in the NAS class, as the baseline does, it is started directly in the PHCH recv class. But when starting in the NAS class, it goes through the RRC class, which starts this counter up, so it will reset, if taking to long. This can be solve by using a RRC class connected to the Co Phy, but this was not tested in time, as the error cause was found to late.

The problem with the missing timer in the RRC is not the cause for all the occurings of the \textit{ilde after MIB-NB} error, especially for when the number of device gets higher. A reason seen, before doing test seen in \autoref{ch:mass_test}, is that the receiver buffer gets out of sync, when the number of devices is to high, which causes a call to the RRC class about out of sync, which reset the system down to the synchronization step. This was thought to be because the MDE was to slow at this part, but as seen from the test for the execution time for the SIB1 messages, does the measurements not rise in execution time, with the higher number of device. So unless that the error limits is very small and it just hits at 13 at this point, the error should be found at another area. A possible solution will be to implement an update function for the receiver buffer, so it will always receive, when it is time.

While under devolopment have the MDE emulated up to 18 devices at once, but with an estimated error rate around 70$\%$. The reason thought to be the reason for the lower number, presented in \autoref{ch:mass_test}, is that the measurements tools have also been using the resources in form of CPU usage. As mention before, is the most common error with higher number of devices, the off sync error, happening in the SIB1 step. If it is a CPU usage problem, the measurement tools can have an influence on the number of devices needed to produce the error and as it is the only difference between the normal testing while in-development and the test seen in this report, it is thought to have an influence.

But even with the lower expected number of devices getting emulated, the concept started by the previous project, have been implemented for another protocol and multiple test indicates that it should be possible to get a higher number of devices, as seen in \autoref{ch:mass_test}. If the baseline code gets fully development, without to many structural changes and the implementations ideas, shown later in \autoref{ch:Future}, the ideal MDE can be developed.




\section{Domain: Energy Consumption}
It was found in \autoref{ch:BatTest} that it is possible to achieve a battery lifetime of more than 10 years on a 5 Wh battery, however it was also discovered that this was not a guarantee. It was found that to achieve this the device is only allowed to transmit for a maximum of 0.468 s per 24 hours. \todo{How realitisk is this result?}

Taking a step back to evaluate the method of finding this value, a couple of issues can be seen. The way the model is designed, limits the precision a bit. Firstly is that TX and RX can not be told apart. This is needed for a couple of different reasons to better the results\todo{Will it be better to know the difference or not}: first is this could be used to approximate the energy spent during the attach and release procedures more accurately, second is it would give way better options for designing a use case including e.g. software updates. The model handles this issue by always assuming a worst case scenario energy consumption, this however leads to the another issue. During the transmit phase is RX included, this lowers the power average power used here, as the model does not assume any relation between $T_{transmit}$ and the throughput. This is not a major issue, but is does not accurately describe most use cases. The third issue is a bit more hidden however, the parameter repetition was set to 1\todo{Will it not make it worse}, this means that any transmission is rather short when this parameter is increase factors like the transmission gap comes into play this is not accounted for in the model. The forth issue is that the model uses a full attach procedure for each attach \todo{also from waking up from PSM?}, this should not be the case in a real scenario, however as this issue makes the model underestimate the lifetime the design objective can still be evaluated.

Fixing these flaws in the model could indeed bring the accuracy of the model up, however it would also complicate the model further. As the model is intended to be as simple as possible, while still providing accurate estimates, this is not desired. To evaluate if the model actually predicts the battery life time accurately would require a longer test run, setting all the parameters and including idle mode and data transmission interval and evaluating the energy consumption over multiple days. This has however not been possible as the UXM used in the project is a shared resource. 

Another concern is that only four parameters was chosen out of a multitude of parameters. This of course could influence the estimate quite a bit. This has been accounted for indirectly as more or less all of these parameters would affect the time a transmission takes, but not the average power consumption. A concern however is that repetition, not only affects the data transfer, but also the attach, release and paging messages. A few other parameters might also affect these procedures, in an uncertain way. Related to this is also the fact that each value of the different parameters has only been measured once, meaning any uncertainty for the individual points can not be evaluated and that independence between all the parameters has been assumed. These might be some of the biggest flaws in the evaluation, which needs to be addressed.

When all of these issues and concerns are taking into account the model still predicts that the main influence the battery lifetime is the transmit time and in the end is this parameter  very much use case dependent. Other parameters is also highly influential such as idle mode timer values, however the scenarios for which they are the main issue is considered quite unrealistic from an operators perspective. To do this, the parameters that influence the time should be investigated, some of the parameters affecting the transmit time has already been investigated by another group at Aalborg University \citep{NDS_report}.



